% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dCVnet_functions.R
\name{dCVreg}
\alias{dCVreg}
\title{Fit a doubly cross-validated elastic-net regularised (generalised) linear model}
\usage{
dCVreg(f, data, nrep_outer = 5, k_outer = 10, nrep_inner = 5,
  k_inner = 10, tuning_searchsize_lambda = 1000, alphalist = seq(from = 0,
  to = 1, by = 0.1), type.measure = "deviance",
  option.selection = "default", option.empirical_cutoff = FALSE,
  debug = FALSE, speedup = FALSE)
}
\arguments{
\item{f}{a two sided formula. LHS must be binary and formula must include an intercept.}

\item{data}{data.frame containing all terms in f.}

\item{nrep_outer}{an integer, the number of repetitions (k-fold outer CV)}

\item{k_outer}{an integer, the k in the outer k-fold CV.}

\item{nrep_inner}{an integer, the number of repetitions (k-fold outer CV)}

\item{k_inner}{an integer, the k in the inner k-fold CV.}

\item{tuning_searchsize_lambda}{an integer, number of gradations between
lambda.min and lambda.max to search.
See \code{glmnet} argument \code{nlambda}.}

\item{alphalist}{a numeric vector of values in [0,1].
Values of alpha to evaluate in inner cross-validation.}

\item{type.measure}{passed to \code{cv.glmnet}.
The loss to use for hyperparameter selection in the inner cross-validation.
Options: \code{"deviance"}, \code{"class"}, \code{"mse"}, \code{"mae"}}

\item{option.selection}{Method for hyperparameter selection in the inner cross-validation.
One of \code{"default"} (lambda at best loss), \code{"lambda.3pc"} (add 3% to the default lambda),
\code{"lambda.1se"} (add 1SE to the default lambda).
Selection between alpha values is not affected by \code{option.selection}.}

\item{option.empirical_cutoff}{Boolian.
Use the empirical proportion of cases as the cutoff for outer CV classification
(affects outer CV performance only). Otherwise classify at 50\% probability.}

\item{debug}{Boolian.
In 'debug' mode inner loop models are retained. This can produce very large return sizes.}

\item{speedup}{Boolian.
Requests the faster \code{"modified.Newton"} method for logistic \code{glmnet}.
See: \code{glmnet}'s \code{type.logistic} argument.}
}
\value{
a dCVnet object.
}
\description{
repeated k-fold cross-validation used to:
    \itemize{
    \item{Produce unbiased estimates of out-of-sample classification performance (outer CV).}
    \item{Select optimal hyperparameters for the elasticnet (inner CV).}}
    Elasticnet hyperparameters are
    \bold{lambda} (the total regularisation penalty)
    and \bold{alpha} (the balance of L1 and L2 regularisation types).
}
\examples{
\dontrun{
iris_class <- dCVreg(f = Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
                     data = subset(iris, iris$Species != c("versicolor")),
                     alphalist = 0.5)}
}
