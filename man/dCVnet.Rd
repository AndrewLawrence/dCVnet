% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dCVnet_main.R
\name{dCVnet}
\alias{dCVnet}
\title{Fit a doubly cross-validated elastic-net regularised (generalised) linear model}
\usage{
dCVnet(f, data, nrep_outer = 2, k_outer = 10, nrep_inner = 5,
  k_inner = 10, alphalist, type.measure, positive = 1,
  option.empirical_cutoff, nlambda, ...)
}
\arguments{
\item{f}{a two sided formula. LHS must be binary and formula must include an intercept.}

\item{data}{data.frame containing all terms in f.}

\item{nrep_outer}{an integer, the number of repetitions (k-fold outer CV)}

\item{k_outer}{an integer, the k in the outer k-fold CV.}

\item{nrep_inner}{an integer, the number of repetitions (k-fold outer CV)}

\item{k_inner}{an integer, the k in the inner k-fold CV.}

\item{alphalist}{a numeric vector of values in \link{0,1}.
Values of alpha to evaluate in inner cross-validation.}

\item{type.measure}{passed to \code{cv.glmnet}.
The loss to use for hyperparameter selection in the inner cross-validation.
Options: \code{"deviance"}, \code{"class"}, \code{"mse"}, \code{"mae"}}

\item{positive}{What level of the outcome is a 'positive' result
(in the sense of a diagnostic test)}

\item{option.empirical_cutoff}{Boolian.
Use the empirical proportion of cases as the cutoff for outer CV classification
(affects outer CV performance only). Otherwise classify at 50\% probability.}

\item{tuning_searchsize_lambda}{an integer, number of gradations between
lambda.min and lambda.max to search.
See \code{glmnet} argument \code{nlambda}.}

\item{option.selection}{Method for hyperparameter selection in the inner cross-validation.
One of \code{"default"} (lambda at best loss), \code{"lambda.3pc"} (add 3% to the default lambda),
\code{"lambda.1se"} (add 1SE to the default lambda).
Selection between alpha values is not affected by \code{option.selection}.}

\item{debug}{Boolian.
In 'debug' mode inner loop models are retained. This can produce very large return sizes.}

\item{speedup}{Boolian.
Requests the faster \code{"modified.Newton"} method for logistic \code{glmnet}.
See: \code{glmnet}'s \code{type.logistic} argument.}
}
\value{
a dCVnet object.
}
\description{
repeated k-fold cross-validation used to:
\itemize{
\item{Produce unbiased estimates of out-of-sample classification performance (outer CV).}
\item{Select optimal hyperparameters for the elasticnet (inner CV).}}
Elasticnet hyperparameters are
\bold{lambda} (the total regularisation penalty)
and \bold{alpha} (the balance of L1 and L2 regularisation types).
}
\examples{
\dontrun{
iris_class <- dCVreg(f = Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
                     data = subset(iris, iris$Species != c("versicolor")),
                     alphalist = 0.5)}
}
