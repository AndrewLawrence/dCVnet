---
title: "dCVnet-imputation"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{dCVnet-imputation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette will demonstrate the options provided for imputation in dCVnet.

Start by loading the prostate dataset (see the "prostate" dCVnet example for more details) and artificially remove some predictor data.

```{r setup}
suppressPackageStartupMessages(suppressWarnings(library(tidyverse)))
library(dCVnet)
theme_set(theme_light())

data("prostate", package = "dCVnet")
# extract outcome y and predictor matrix x:
y <- prostate[, 1]
x <- prostate[, c(-1, -10)]

# make a version of x with ~10% missing values:
xmiss <- x
xmiss$lcp[c(39, 64, 71, 74, 75, 76, 83, 88, 94, 95)] <- NA

```

We have induced Missing At Random (MAR) missingness for this dataset for a single variable. Specifically, ten of the larger values of the variable `lcp` were removed.

This variable was chosen because:

1)  `lcp` is a strong predictor. We want to demonstrate the potential utility of imputation and if missing values are only in predictors without much predictive power then the impact of imputing their values will be small.

2)  `lcp` is correlated quite strongly (\~0.67) with `svi`, which has no missing values. As a result we expect conditional imputation models will be able to use `svi`, and other features, to do a reasonable job of imputing the missing values of `lcp`.

```{r missingness}
# Plot to show the missing values of lcp in context of svi:
prostate %>%
  cbind(., missingness = is.na(xmiss$lcp)) %>%
  ggplot(aes(y = lcp, x = as.factor(svi), colour = missingness)) +
  geom_point() +
  xlab("svi")

```

Imputation in dCVnet is controlled by a number of option arguments:

-   `opt.use_imputation` (`FALSE`/`TRUE`) - determines if imputation is used. The default (`FALSE`) behaviour is to filter out any observations with any missing data in predictors or outcome and run dCVnet on the complete cases dataset.

-   `opt.imputation_method`, use one of the following imputation methods:

    -   `"mean"`
    -   `"knn"`
    -   `"missForestPredict"`

To demonstrate imputation in dCVnet we will fit (and cross-validate) five dCVnet models:

-   `"orig"` - A standard dCVnet run on the original data without any missing values. The performance of this model is the "true" performance we wish to recover by employing imputation.
-   `"cc"` - A dCVnet model run without imputation. The performance of this model should be negatively impacted by the 10% fewer cases and the biased coefficients resulting from the MAR missingness of the `lcp` variable.
-   `"meanimp"` - A dCVnet model with unconditional mean imputation of missing values. This will have the same number of cases as `"orig"` but the imputed values of `lcp` will be biased so performance may not improve much relative to `"cc"`.
-   `"knnimp"` and `"rfimp"` - These are conditional imputation methods so should produce better imputations of missing svi scores than `"meanimp"`. Hopefully will recover much of the performance difference between `"orig"` and `"cc"`.

```{r fit_models, echo=TRUE, eval = FALSE}
# Note: the models take a long time to fit, so this vignette loads stored
#       results so it compiles quickly.
model_settings <- data.frame(
  labels = c("orig", "cc", "meanimp", "knnimp", "rfimp"),
  data = c(1, 2, 2, 2, 2),
  use_imp = c(FALSE, FALSE, TRUE, TRUE, TRUE),
  imp_meth = rep(c("mean", "knn", "missForestPredict"), times = c(3, 1, 1))
)

data_list <- list(x, xmiss)

models <- map(set_names(seq.int(nrow(model_settings)), model_settings$labels),
              ~ dCVnet(
                y = y,
                data = data_list[model_settings$data[.x]],
                f = "~.",
                family = "gaussian",
                alphalist = 1.0,
                k_inner = 10,
                k_outer = 10,
                nrep_inner = 25,
                nrep_outer = 25,
                opt.use_imputation = model_settings$use_imp[.x],
                opt.imputation_method = model_settings$imp_meth[.x]
              ))

cv_rmse_results <- map_dfr(
  models,
  ~ report_performance_summary(.x, short = TRUE) %>%
    filter(Measure == "RMSE") %>%
    select(mean, sd),
  .id = "model"
)

```

```{r load_results, include=FALSE}


cv_rmse_results <- structure(list(
  model = c("orig", "cc", "meanimp", "knnimp", "rfimp"),
  mean = c(
    0.739631127378644,
    0.773580289068649,
    0.776861612118786,
    0.759540904081737,
    0.756714809471389
  ),
  sd = c(
    0.0116423343714006,
    0.0146832811277592,
    0.0114885054274784,
    0.011323831581812,
    0.0109847869670491
  )
),
class = "data.frame",
row.names = c(NA, -5L))

```

Now, inspect the output:

```{r inspect}
cv_rmse_results %>% knitr::kable(digits = 3)

cv_rmse_results %>%
  mutate(model = factor(model, levels = model)) %>%
  mutate(imputation = factor(model %in% c("orig", "cc"),
                             levels = c(TRUE, FALSE),
                             labels = c("no", "yes"))) %>%
  ggplot(aes(y = mean,
             ymin = mean - 2 * sd,
             ymax = mean + 2 * sd,
             x = model,
             colour = imputation)) +
  geom_errorbar(width = 0.2) +
  scale_colour_manual(values = c(no = "darkblue", yes = "darkred")) +
  geom_point() +
  ylab("CV-RMSE") +
  theme(axis.text.x = element_text(angle = 45))
```

First, as expected given the reduced sample size and induced bias, relative to the non-missing data (`"orig"`), the complete-cases (`"cc")` model has a worse CV prediction performance (RMSE) with greater variability of CV-RMSE over CV-repetitions (indicated by error bars).

The first imputation method (unconditional mean imputation; `"meanimp"`) does not noticeably de-bias performance back towards the "true" model (`"orig"`), but it does slightly narrow the variability.

In contrast, the k-nearest neighbours (`"knnimp"`) and random-forest imputation (`"rfimp"`) approaches bring the mean CV-prediction performance closer to the "true" non-missing model's performance (albeit not perfectly) and also narrows the variability to be closer to that of the "true" dataset.

*In this simulation we demonstrated that including conditional single imputation (knn or random forest) in a dCVnet prediction model can yield improved cross-validated results - ones closer to the unavailable complete data than a complete-cases approach or unsophisticated mean imputation.*

## dCVnet Imputation Details

dCVnet supports single imputation methods. Imputation is either unconditional (the sample "mean" of observed values, or conditional. The two conditional methods are:

-   k-nearest neighbour method ("knn") from the caret package, which imputes missing values as the average from the k=5 nearest observations).

-   The "missForestPredict" approach to missing data employing iterative random forests.

Imputation of all types is conducted on the x-matrix of predictor variables and occurs *after* expansion for dummy variables and formula terms; e.g. `poly(age,2)` produces two variables for a single predictor column called age.

For the cross-validated outputs of dCVnet (i.e. excluding the production model) imputation is conducted independently for each fold of the repeated k-fold CV and so estimates of cross-validated model performance are not inflated by data-leakage related to imputation.

For practical reasons, all imputation methods in dCVnet must allow "prediction" i.e. we must be able to generate imputed values for new observations not used in the original imputation model. Specifically, for **mean imputation** this is as simple as imputing missing held-out data with the mean calculated from the test data. For **knn imputation** it means each held-out subject with missing data has their nearest-neighbours identified from the train dataset. For [**missForest**](https://github.com/stekhoven/missForest) **imputation** we use the [missForestPredict](https://github.com/sibipx/missForestPredict) package to allow prediction of the held-out data from the train data imputation model.

When dCVnet fits the **production model** this is is done to the full dataset and an imputation model is generated for the full dataset. The dCVnet object then includes this full-data imputation model, and using the `predict.dCVnet` method will incorporate the requested imputation type for missing data in the new observations predictions are requested for.

### Imputation: Outcome

dCVnet presently does not use the outcome (`y`) in the imputation model. When a prediction model is eventually employed we will not have access to the true y label, and so any improvement in performance due to using y in imputation will not be expected to generalise. However, the development of the model may be improved by including y (this distinction is sometimes called pragmatic vs. ideal performance in prediction modelling) so in future imputation using y may be added.
